{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 40), (11880, 40), (14358, 40), (47520,), (11880,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.read_csv('Data/train_features.csv')\n",
    "X_test = pd.read_csv('Data/test_features.csv')\n",
    "target = pd.read_csv('Data/train_labels.csv')\n",
    "label = target['status_group']\n",
    "\n",
    "# Only used to test collapsing problem to binomial classification\n",
    "target['encoded'] = target['status_group'].replace({\n",
    "    'functional': 2,\n",
    "    'non functional': 0,\n",
    "    'functional needs repair':1\n",
    "})\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>% NA?</th>\n",
       "      <th>Unique values</th>\n",
       "      <th>Correlation w/Target</th>\n",
       "      <th>Hypothesis</th>\n",
       "      <th>Baseline Approach</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>amount_tsh</td>\n",
       "      <td>Amount of water available to waterpoint</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>Important</td>\n",
       "      <td>Standardize Data</td>\n",
       "      <td>Highly Positive Skew (70% = 0), should address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>date_recorded</td>\n",
       "      <td>The data the observation was entered</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Important</td>\n",
       "      <td>Create columns for month and year</td>\n",
       "      <td>Recording from 10/2002 to 12/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>funder</td>\n",
       "      <td>who funded the wall</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>1897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Long Tail of funders, consider binning, invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gps_height</td>\n",
       "      <td>altitude of the well</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2428</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>Important</td>\n",
       "      <td>Standardize Data</td>\n",
       "      <td>Distribution positively skewed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>installer</td>\n",
       "      <td>orgaization that installed the well</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>2145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Important</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>31% installed by same group, long-tail of smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>longitude</td>\n",
       "      <td>GPS coordinate</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57516</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Weird distribution of values near zero (error?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>latitude</td>\n",
       "      <td>GPS coordinate</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57517</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>wpt_name</td>\n",
       "      <td>Name of the waterpoint if there is one</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>6% of obs. Have value of 'none'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>num_private</td>\n",
       "      <td>?</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>98% of values = 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>basin</td>\n",
       "      <td>Geographic water basin</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Majority category is 17% of population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>subvillage</td>\n",
       "      <td>geographic location</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>19287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Extremely High Cardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>region</td>\n",
       "      <td>geographic location</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Adopt alternative encoding measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>region_code</td>\n",
       "      <td>geographic location (coded)</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore (perfectly collinear with prior)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>district_code</td>\n",
       "      <td>geographic location (coded)</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.0650</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore (perfectly collinear with prior)</td>\n",
       "      <td>Possibly bin low freq. cats. to reduce cardina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>lga</td>\n",
       "      <td>geographic location</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Encode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>ward</td>\n",
       "      <td>geographic location</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Encode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>population</td>\n",
       "      <td>population around the well</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardize Data</td>\n",
       "      <td>Large Outliers, 30% of values = 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>public_meeting</td>\n",
       "      <td>True/False</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Include, no processing needed</td>\n",
       "      <td>90% True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>recorded_by</td>\n",
       "      <td>group entering this observation</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore, Drop, no variation across obs.</td>\n",
       "      <td>Only one unique value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>scheme_management</td>\n",
       "      <td>Who operates the waterpoint</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Create binary col for majority cat.</td>\n",
       "      <td>66% managed by one entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>scheme_name</td>\n",
       "      <td>who operates the waterpoint</td>\n",
       "      <td>object</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>2696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Appears very noisy, low priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>permit</td>\n",
       "      <td>if the water is permitted</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Include, no processing needed</td>\n",
       "      <td>68% true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>construction_year</td>\n",
       "      <td>year the waterpoint was constructed</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Create age feature</td>\n",
       "      <td>34.8% = 0 (likely unkown)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>extraction_type</td>\n",
       "      <td>the kind of extraction the waterpoint uses</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore, collinear with class feature</td>\n",
       "      <td>Collapse low freq and other categories to redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>extraction_type_group</td>\n",
       "      <td>the kind of extraction the waterpoint uses</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore, collinear with class feature</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>extraction_type_class</td>\n",
       "      <td>the kind of extraction the waterpoint uses</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>gravity is majority cat. w/45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>how the waterpoint is managed</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Appears related to scheme_management feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>management_group</td>\n",
       "      <td>how the waterpoint is managed</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Majority class is 88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>payment</td>\n",
       "      <td>What the water costs</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Majority class is 43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>payment_type</td>\n",
       "      <td>What the water costs</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Ignore (perfectly collinear with prior)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>water_quality</td>\n",
       "      <td>the quality of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore (other col. Contains info)</td>\n",
       "      <td>majority cat. Is 85.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>quality_group</td>\n",
       "      <td>the quality of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Bin low freq. cats, One Hot Encode</td>\n",
       "      <td>majority cat. Is 85.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>quantity</td>\n",
       "      <td>the quantity of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>majority cat. Is 55.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>quantity_group</td>\n",
       "      <td>the quantity of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Ignore (perfectly collinear with prior)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>source</td>\n",
       "      <td>the source of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore (other col. Contains info)</td>\n",
       "      <td>May be helpful to use this in future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>source_type</td>\n",
       "      <td>the source of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>source_class</td>\n",
       "      <td>the source of the water</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Consider relabelling unkown as majority class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>waterpoint_type</td>\n",
       "      <td>The kind of waterpoint</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>One Hot Encode</td>\n",
       "      <td>Majority class is 48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>waterpoint_type_group</td>\n",
       "      <td>The kind of waterpoint</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Ignore (other col. Contains info)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                Feature                                 Description  \\\n",
       "0       1             amount_tsh     Amount of water available to waterpoint   \n",
       "1       2          date_recorded        The data the observation was entered   \n",
       "2       3                 funder                         who funded the wall   \n",
       "3       4             gps_height                        altitude of the well   \n",
       "4       5              installer         orgaization that installed the well   \n",
       "5       6              longitude                              GPS coordinate   \n",
       "6       7               latitude                              GPS coordinate   \n",
       "7       8               wpt_name      Name of the waterpoint if there is one   \n",
       "8       9            num_private                                           ?   \n",
       "9      10                  basin                      Geographic water basin   \n",
       "10     11             subvillage                         geographic location   \n",
       "11     12                 region                         geographic location   \n",
       "12     13            region_code                 geographic location (coded)   \n",
       "13     14          district_code                 geographic location (coded)   \n",
       "14     15                    lga                         geographic location   \n",
       "15     16                   ward                         geographic location   \n",
       "16     17             population                  population around the well   \n",
       "17     18         public_meeting                                  True/False   \n",
       "18     19            recorded_by             group entering this observation   \n",
       "19     20      scheme_management                 Who operates the waterpoint   \n",
       "20     21            scheme_name                 who operates the waterpoint   \n",
       "21     22                 permit                   if the water is permitted   \n",
       "22     23      construction_year         year the waterpoint was constructed   \n",
       "23     24        extraction_type  the kind of extraction the waterpoint uses   \n",
       "24     25  extraction_type_group  the kind of extraction the waterpoint uses   \n",
       "25     26  extraction_type_class  the kind of extraction the waterpoint uses   \n",
       "26     27             management               how the waterpoint is managed   \n",
       "27     28       management_group               how the waterpoint is managed   \n",
       "28     29                payment                        What the water costs   \n",
       "29     30           payment_type                        What the water costs   \n",
       "30     31          water_quality                    the quality of the water   \n",
       "31     32          quality_group                    the quality of the water   \n",
       "32     33               quantity                   the quantity of the water   \n",
       "33     34         quantity_group                   the quantity of the water   \n",
       "34     35                 source                     the source of the water   \n",
       "35     36            source_type                     the source of the water   \n",
       "36     37          source_class                      the source of the water   \n",
       "37     38        waterpoint_type                      The kind of waterpoint   \n",
       "38     39  waterpoint_type_group                      The kind of waterpoint   \n",
       "\n",
       "     Dtype   % NA?  Unique values  Correlation w/Target   Hypothesis  \\\n",
       "0    float     NaN             98                0.0530    Important   \n",
       "1   object     NaN            356                   NaN    Important   \n",
       "2   object  0.0610           1897                   NaN     Moderate   \n",
       "3      int     NaN           2428                0.1100    Important   \n",
       "4   object  0.0610           2145                   NaN    Important   \n",
       "5    float     NaN          57516               -0.0040     Moderate   \n",
       "6    float     NaN          57517                0.0140     Moderate   \n",
       "7   object     NaN          37400                   NaN          Low   \n",
       "8      int     NaN             65                0.0005          Low   \n",
       "9   object     NaN              9                   NaN          Low   \n",
       "10  object  0.0006          19287                   NaN          Low   \n",
       "11  object     NaN             21                   NaN     Moderate   \n",
       "12     int     NaN             27               -0.1080     Moderate   \n",
       "13     int     NaN             20               -0.0650          Low   \n",
       "14  object     NaN            125                   NaN          Low   \n",
       "15  object     NaN           2092                   NaN          Low   \n",
       "16     int     NaN           1049                0.0145          NaN   \n",
       "17  object  0.0560              2                   NaN     Moderate   \n",
       "18  object     NaN              1                   NaN          Low   \n",
       "19  object  0.0650             12                   NaN     Moderate   \n",
       "20  object  0.4740           2696                   NaN          Low   \n",
       "21  object  0.0510              2                   NaN     Moderate   \n",
       "22     int     NaN             55                0.0430     Moderate   \n",
       "23  object     NaN             18                   NaN     Moderate   \n",
       "24  object     NaN             13                   NaN     Moderate   \n",
       "25  object     NaN              7                   NaN         High   \n",
       "26  object     NaN             12                   NaN     Moderate   \n",
       "27  object     NaN              5                   NaN     Moderate   \n",
       "28  object     NaN              7                   NaN         High   \n",
       "29  object     NaN              7                   NaN          Low   \n",
       "30  object     NaN              8                   NaN     Moderate   \n",
       "31  object     NaN              6                   NaN     Moderate   \n",
       "32  object     NaN              5                   NaN         High   \n",
       "33  object     NaN              5                   NaN         High   \n",
       "34  object     NaN             10                   NaN     Moderate   \n",
       "35  object     NaN              7                   NaN     Moderate   \n",
       "36  object     NaN              3                   NaN     Moderate   \n",
       "37  object     NaN              7                   NaN     Moderate   \n",
       "38  object     NaN              6                   NaN     Moderate   \n",
       "\n",
       "                          Baseline Approach  \\\n",
       "0                          Standardize Data   \n",
       "1         Create columns for month and year   \n",
       "2                                    Ignore   \n",
       "3                          Standardize Data   \n",
       "4                                    Ignore   \n",
       "5                                    Ignore   \n",
       "6                                    Ignore   \n",
       "7                                    Ignore   \n",
       "8                                    Ignore   \n",
       "9                            One Hot Encode   \n",
       "10                                   Ignore   \n",
       "11                           One Hot Encode   \n",
       "12  Ignore (perfectly collinear with prior)   \n",
       "13  Ignore (perfectly collinear with prior)   \n",
       "14                                   Ignore   \n",
       "15                                   Ignore   \n",
       "16                         Standardize Data   \n",
       "17            Include, no processing needed   \n",
       "18   Ignore, Drop, no variation across obs.   \n",
       "19      Create binary col for majority cat.   \n",
       "20                                   Ignore   \n",
       "21            Include, no processing needed   \n",
       "22                       Create age feature   \n",
       "23     Ignore, collinear with class feature   \n",
       "24     Ignore, collinear with class feature   \n",
       "25                           One Hot Encode   \n",
       "26                                   Ignore   \n",
       "27                           One Hot Encode   \n",
       "28                           One Hot Encode   \n",
       "29  Ignore (perfectly collinear with prior)   \n",
       "30        Ignore (other col. Contains info)   \n",
       "31       Bin low freq. cats, One Hot Encode   \n",
       "32                           One Hot Encode   \n",
       "33  Ignore (perfectly collinear with prior)   \n",
       "34        Ignore (other col. Contains info)   \n",
       "35                           One Hot Encode   \n",
       "36                           One Hot Encode   \n",
       "37                           One Hot Encode   \n",
       "38        Ignore (other col. Contains info)   \n",
       "\n",
       "                                                Notes  \n",
       "0   Highly Positive Skew (70% = 0), should address...  \n",
       "1                   Recording from 10/2002 to 12/2013  \n",
       "2   Long Tail of funders, consider binning, invest...  \n",
       "3                      Distribution positively skewed  \n",
       "4   31% installed by same group, long-tail of smal...  \n",
       "5   Weird distribution of values near zero (error?...  \n",
       "6                                                 NaN  \n",
       "7                     6% of obs. Have value of 'none'  \n",
       "8                                   98% of values = 0  \n",
       "9              Majority category is 17% of population  \n",
       "10                         Extremely High Cardinality  \n",
       "11                 Adopt alternative encoding measure  \n",
       "12                                                NaN  \n",
       "13  Possibly bin low freq. cats. to reduce cardina...  \n",
       "14                                             Encode  \n",
       "15                                             Encode  \n",
       "16                  Large Outliers, 30% of values = 0  \n",
       "17                                           90% True  \n",
       "18                              Only one unique value  \n",
       "19                          66% managed by one entity  \n",
       "20                   Appears very noisy, low priority  \n",
       "21                                           68% true  \n",
       "22                          34.8% = 0 (likely unkown)  \n",
       "23  Collapse low freq and other categories to redu...  \n",
       "24                                                NaN  \n",
       "25                     gravity is majority cat. w/45%  \n",
       "26       Appears related to scheme_management feature  \n",
       "27                              Majority class is 88%  \n",
       "28                              Majority class is 43%  \n",
       "29                                                NaN  \n",
       "30                             majority cat. Is 85.5%  \n",
       "31                             majority cat. Is 85.5%  \n",
       "32                             majority cat. Is 55.8%  \n",
       "33                                                NaN  \n",
       "34               May be helpful to use this in future  \n",
       "35                                                NaN  \n",
       "36  Consider relabelling unkown as majority class ...  \n",
       "37                              Majority class is 48%  \n",
       "38                                                NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_excel('Data_Dictionary.xlsx', skipfooter=3)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['amount_tsh',\n",
    "    'date_recorded',\n",
    "    'gps_height',\n",
    "    'basin',\n",
    "    'region',\n",
    "    'district_code',\n",
    "    'population',\n",
    "    'public_meeting',\n",
    "    'scheme_management',\n",
    "    'permit',\n",
    "    'construction_year',\n",
    "    'extraction_type_class',\n",
    "    'management_group',\n",
    "    'payment',\n",
    "    'quality_group',\n",
    "    'quantity',\n",
    "    'source_type',\n",
    "    'source_class', \n",
    "    'waterpoint_type',\n",
    "    'funder',\n",
    "    'installer', \n",
    "    'latitude',\n",
    "    'longitude']\n",
    "\n",
    "def select_features(df, features):\n",
    "    '''\n",
    "    Subsets dataframe based on list of columns names accepted \n",
    "    as a parameter.\n",
    "    '''\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 23), (11880, 23), (14358, 23))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = select_features(X_train, features=selected_features)\n",
    "X_val = select_features(X_val, features=selected_features)\n",
    "X_test = select_features(X_test, features=selected_features)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only used to test collapsing problem to binomial classification\n",
    "target['encoded'] = target['status_group'].replace({\n",
    "    'functional': 1,\n",
    "    'non functional': 0,\n",
    "    'functional needs repair':0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_impute(X):\n",
    "    ''' Adapted directly from Dakota P.'s awesome work '''\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Convert all strings in object columns to lowercase\n",
    "    cat_features = X.select_dtypes('object').columns.tolist()\n",
    "    for feature in cat_features:\n",
    "        X[feature] = X[feature].str.lower()\n",
    "    \n",
    "    # Replace -2.000000e-08 with np.nan (not showing as zero due to datatype)\n",
    "    X['latitude'] = X['latitude'].replace( -2.000000e-08, np.nan)\n",
    "    \n",
    "    impute_features = ['gps_height', 'population', 'amount_tsh', 'construction_year', 'latitude', 'longitude']\n",
    "\n",
    "    for feature in impute_features:\n",
    "        # Replace values=0.0 with np.nan (0.0 appears to indicate missing values in dataset)\n",
    "        X[feature] = X[feature].replace(0, np.nan)\n",
    "        \n",
    "        # Note, hardcoded train when calculating mean to avoid leakage into test data\n",
    "        # If District code available replace NA's with mean value of other well in the same district \n",
    "        X[feature] = X[feature].fillna( X.groupby(['region', 'district_code'])[feature].transform('mean') )\n",
    "        # If no district code, replace NA's  with mean value of other wells in the same region\n",
    "        X[feature] = X[feature].fillna( X.groupby(['region'])[feature].transform('mean') )\n",
    "        # If no district and no region, replace NA's with mean value of all wells\n",
    "        X[feature] = X[feature].fillna( X[feature].mean() )\n",
    "    \n",
    "    # Convert Boolean Features to int\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 23), (11880, 23), (14358, 23))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = smart_impute(X_train)\n",
    "X_val = smart_impute(X_val)\n",
    "X_test = smart_impute(X_test)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_features(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # Create features to capture well distance from other wells\n",
    "    long_mean = X_train['longitude'].mean()\n",
    "    lat_mean = X_train['latitude'].mean()\n",
    "    X['distance'] = np.sqrt((X['longitude'] - long_mean)**2 + \n",
    "                                  (X['latitude'] - lat_mean)**2)\n",
    "    X['distance_height'] = np.sqrt((X['gps_height']**2 + X['longitude'] - long_mean)**2 + \n",
    "                                         (X['latitude'] - lat_mean)**2)\n",
    "    \n",
    "    # Create month and year features from the recorded data feature\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'])\n",
    "    X['date_recorded_month'] = X['date_recorded'].dt.month\n",
    "    X['date_recorded_year'] = X['date_recorded'].dt.year\n",
    "    \n",
    "    # Years since construction feature\n",
    "    X['Years_Since_built'] = X['construction_year'] - X['date_recorded_year']\n",
    "    \n",
    "    # Create feature for seasons in Tanzania\n",
    "    X['Hot_Dry_Season'] = (X['date_recorded_month'] == 12) | (X['date_recorded_month'] < 3)\n",
    "    X['Heavy_Rain_Season'] = (X['date_recorded_month'] > 4) & (X['date_recorded_month'] < 6)\n",
    "    X['Cool_Dry_Season'] = (X['date_recorded_month'] > 5) & (X['date_recorded_month'] < 11)\n",
    "    X['Moderate_Rain'] = (X['date_recorded_month'] == 11) | (X['date_recorded_month'] == 3)\n",
    "    \n",
    "    #Bin low freq. categories into 'other' \n",
    "    X['scheme_management'] = X['scheme_management'].replace({\n",
    "        'SWC':'Other',\n",
    "        'Trust':'Other',\n",
    "        'None':'Other'\n",
    "    })\n",
    "    \n",
    "    #Create unkown category for missing values in scheme management column\n",
    "    X['scheme_management'] = X['scheme_management'].fillna('unknown')\n",
    "    X['permit'] = X['permit'].fillna(False)\n",
    "    X['public_meeting'] = X['public_meeting'].fillna(True)\n",
    "    \n",
    "    #Create age category out of construction_year\n",
    "    #Bin 0 values as -1\n",
    "    X['pump_age'] = ( 2014 - X['construction_year'] )\n",
    "    X['pump_age'] = X['pump_age'].replace({2014:-1})\n",
    "    \n",
    "    # Create Installer Features\n",
    "    X['DWE_Installer'] = (X['installer'] == 'DWE')\n",
    "    X['Gov_Installer'] = (X['installer'] == 'Government')\n",
    "\n",
    "    one_time_install = train['installer'].value_counts()[train['installer'].value_counts() == 1]\n",
    "    X['One_Time_Installer'] = X['installer'].isin(one_time_install.index)\n",
    "\n",
    "    small_install = train['installer'].value_counts()[ (train['installer'].value_counts() < 10) & (train['installer'].value_counts() > 1) ]\n",
    "    X['Small_Installer'] = X['installer'].isin(small_install.index)\n",
    "\n",
    "    big_install = (( train['installer'].value_counts() >= 10 ) == True)\n",
    "    X['Big_Installer'] = X['installer'].isin(big_install.index)\n",
    "    \n",
    "    # Create Funder Features\n",
    "    X['Tanzania_Gov_Funder'] = (X['funder'] == 'Government Of Tanzania')\n",
    "\n",
    "    one_time_funder = train['funder'].value_counts()[train['funder'].value_counts() == 1]\n",
    "    X['One_Time_Funder'] = X['funder'].isin(one_time_funder.index)\n",
    "\n",
    "    small_funder = train['funder'].value_counts()[ (train['funder'].value_counts() < 10) & (train['funder'].value_counts() > 1) ]\n",
    "    X['Small_Funder'] = X['funder'].isin(small_funder.index)\n",
    "\n",
    "    big_funder = (( train['funder'].value_counts() >= 10 ) == True)\n",
    "    X['Big_Funder'] = X['funder'].isin(big_funder.index)\n",
    "    \n",
    "    # Create interaction between amount of water avaialable and population\n",
    "    X['pop*amount_tsh'] = X['population'] * X['amount_tsh']\n",
    "    X['pop/amount_tsh'] = X['population'] / X['amount_tsh']\n",
    "    X['pop/amount_tsh'] = X['pop/amount_tsh'].replace(np.inf, 3000)\n",
    "    \n",
    "    X['pop**2'] = X['population'] ** 2\n",
    "    \n",
    "    # Create interaction between amount of water avaialable and height\n",
    "    X['gps_height*amount_tsh'] = X['gps_height'] * X['amount_tsh']\n",
    "    \n",
    "    # Polynomial gps_Height\n",
    "    X['gps_height**2'] = X['gps_height'] ** 2\n",
    "    X['gps_height**3'] = X['gps_height'] ** 3\n",
    "    \n",
    "    # Interaction between latitude and height\n",
    "    X['latitude*height*amount'] = X['latitude'] * X['gps_height'] * X['amount_tsh']\n",
    "    X['latitude*height'] = X['latitude'] * X['gps_height']\n",
    "    \n",
    "    # Create Binned Features\n",
    "    labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "    X['gps_height_binned'] = pd.cut(x=X['gps_height'], bins=10, labels=labels)\n",
    "    X['pump_age_binned'] = pd.cut(x=X['pump_age'], bins=10, labels=labels)\n",
    "    X['amount_tsh_binned'] = pd.cut(x=X['amount_tsh'], bins=10, labels=labels)\n",
    "    X['longitude_binned'] = pd.cut(x=X['longitude'], bins=10, labels=labels)\n",
    "    X['latitude_binned'] = pd.cut(x=X['latitude'], bins=10, labels=labels)\n",
    "    \n",
    "    # Convert Binned Features to int datatype\n",
    "    X['gps_height_binned'] = X['gps_height_binned'].astype(int)\n",
    "    X['pump_age_binned'] = X['pump_age_binned'].astype(int)\n",
    "    X['amount_tsh_binned'] = X['amount_tsh_binned'].astype(int)\n",
    "    X['longitude_binned'] = X['longitude_binned'].astype(int)\n",
    "    X['latitude_binned'] = X['latitude_binned'].astype(int)\n",
    "    \n",
    "    # Pumps Funded and Built by Tanzania Government\n",
    "    X['Gov_Funded_Gov_Built'] = X['Tanzania_Gov_Funder'] * X['DWE_Installer'].astype(int)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 56), (11880, 56), (14358, 56))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = wrangle_features(X_test)\n",
    "X_val = wrangle_features(X_val)\n",
    "X_train = wrangle_features(X_train)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Composite Scores (Additional Feature Engineering) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score(X, feature):\n",
    "    rel_score = pd.crosstab(X_train[feature], y_train)\n",
    "    rel_score = pd.DataFrame(rel_score)\n",
    "    \n",
    "    new_feature = feature + '_rel_score'\n",
    "    total = rel_score['functional'] + rel_score['functional needs repair'] + rel_score['non functional']\n",
    "    rel_score[new_feature] = rel_score['functional'] / total\n",
    "    \n",
    "    rel_score = rel_score.reset_index()\n",
    "    rel_score = rel_score[ [feature, new_feature] ]\n",
    "    \n",
    "    X = pd.merge(X, rel_score, how='left', on=feature)\n",
    "    X[new_feature] = X[new_feature].fillna(0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_scores(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Create Reliability Scores\n",
    "    rel_cols = ['installer', 'scheme_management', 'management_group', 'payment', 'extraction_type_class',\n",
    "               'waterpoint_type', 'pump_age_binned', 'gps_height_binned', 'amount_tsh_binned', 'longitude_binned',\n",
    "               'latitude_binned', 'region', 'basin', 'district_code']\n",
    "    \n",
    "    for col in rel_cols:\n",
    "        X = create_score(X, col)\n",
    "    \n",
    "    # Create Composite Scores\n",
    "    X['Management_Score'] = X['installer_rel_score'] + X['scheme_management_rel_score'] + X['management_group_rel_score']\n",
    "    X['Condition_Score'] = X['gps_height_binned_rel_score'] + X['amount_tsh_binned_rel_score'] + X['latitude_binned_rel_score'] + X['longitude_binned_rel_score']\n",
    "    X['Tech_Score'] = X['payment_rel_score'] + X['pump_age_binned_rel_score'] + X['extraction_type_class_rel_score'] + X['waterpoint_type_rel_score']\n",
    "    \n",
    "    X['Overall_Reliability_Score'] = X['Management_Score'] + X['Condition_Score'] + X['Tech_Score']\n",
    "    X['Overall_Reliability_Score**2'] = X['Overall_Reliability_Score'] ** 2 \n",
    "    \n",
    "    # Public Support Score \n",
    "    X['Public_Support'] = X['payment_rel_score'] + X['public_meeting'] + X['permit']\n",
    "    \n",
    "    # Location Score\n",
    "    X['Location_Score'] = X['basin_rel_score'] + X['district_code_rel_score'] + X['region_rel_score']\n",
    "    \n",
    "    # Location * Condition\n",
    "    X['Location*Condition'] = X['Location_Score'] + X['Condition_Score']\n",
    "    X['Location*Condition**2'] = X['Location*Condition'] ** 2\n",
    "    \n",
    "    # Public Support and Location\n",
    "    X['Public_Support+Loc'] = X['Public_Support'] + X['Location_Score']\n",
    "    \n",
    "    # Site Score\n",
    "    X['Site_Score'] = X['Location_Score'] + X['Public_Support'] + X['Overall_Reliability_Score']\n",
    "    X['Site_Score**2'] = X['Site_Score'] ** 2\n",
    "    \n",
    "    # Negative Correlated Features\n",
    "    X['dry&high'] = (X['Hot_Dry_Season'] | X['Cool_Dry_Season']) * X['latitude*height']\n",
    "    X['Pump_Age*Pop/Amount_tsg'] = X['pump_age'] * X['pop/amount_tsh']\n",
    "    X['pump_age_binned**2'] = X['pump_age_binned'] ** 2\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = composite_scores(X_train)\n",
    "# X_val = composite_scores(X_val)\n",
    "# X_test = composite_scores(X_test)\n",
    "\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Drop unecessary columns\n",
    "    drop_cols = ['date_recorded', 'funder', 'installer', 'construction_year']\n",
    "    X = X.drop(columns=drop_cols)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 52), (11880, 52), (14358, 52))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = drop_cols(X_train)\n",
    "X_val = drop_cols(X_val)\n",
    "X_test = drop_cols(X_test)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "def one_hot(X_train, X_val, X_test):\n",
    "    # Features to one hot encode\n",
    "    one_hot_cols = ['extraction_type_class', 'payment', 'quality_group', \n",
    "                    'quantity', 'source_class', 'waterpoint_type', 'basin', 'source_type', 'region', 'scheme_management',\n",
    "                    'management_group']\n",
    "    \n",
    "    # Initialize and transform relevant features\n",
    "    encoder = ce.OneHotEncoder(cols=one_hot_cols, use_cat_names=True)\n",
    "    \n",
    "    # Note, train hardcoded to avoid overfitting test data\n",
    "    encoder.fit(X_train)\n",
    "    train_encoded = encoder.transform(X_train)\n",
    "    val_encoded = encoder.transform(X_val)\n",
    "    test_encoded = encoder.transform(X_test)\n",
    "    \n",
    "    train_encoded, val_encoded = train_encoded.align(val_encoded, join='left', axis=1)\n",
    "    train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1)\n",
    "    \n",
    "    return train_encoded, val_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 131), (11880, 131), (14358, 131))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, X_test = one_hot(X_train, X_val, X_test)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.tolist() == X_val.columns.tolist() == X_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "def ordinal(X):\n",
    "    ord_cols = ['extraction_type_class', 'payment', 'quality_group', \n",
    "                    'quantity', 'source_class', 'waterpoint_type', 'basin', 'source_type', 'region', 'scheme_management',\n",
    "                    'management_group']\n",
    "    \n",
    "    # Initialize and transform relevant features\n",
    "    encoder = ce.OrdinalEncoder(cols=ord_cols)\n",
    "    \n",
    "    # Note, train hardcoded to avoid overfitting test data\n",
    "    encoder.fit(X_train)\n",
    "    X = encoder.transform(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = ordinal(X_train)\n",
    "# X_val = ordinal(X_val)\n",
    "# X_test = ordinal(X_test)\n",
    "\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Additional Features Based on Encoded Features \n",
    "\n",
    "- Only intended to be used with OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_func_features(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Convert boolean cols to ints\n",
    "    X = X.applymap(lambda x: 1 if x == True else x)\n",
    "    X = X.applymap(lambda x: 0 if x == False else x)\n",
    "    \n",
    "    X['quantity_dry*pump_age/amount'] = X['quantity_dry'] / X['Pump_Age*Pop/Amount_tsg']\n",
    "    \n",
    "    X['Condition_Risk'] = X['quantity_dry'] + X['waterpoint_type_other'] + X['extraction_type_class_other'] + X['quality_group_unknown']\n",
    "    X['Condition**2'] = X['Condition_Risk'] ** 2\n",
    "    \n",
    "    X['Tech_Risk'] = X['extraction_type_class_motorpump'] + X['waterpoint_type_communal standpipe multiple'] + X['waterpoint_type_other']\n",
    "    X['Tech_Risk**2'] = X['Tech_Risk'] ** 2\n",
    "    \n",
    "    X['Non_Tech_Risk*Pump_age'] = X['Tech_Risk'] * X['pump_age']\n",
    "    \n",
    "    X['Management_Risk'] = X['Tanzania_Gov_Funder'] + X['Gov_Installer'] + X['payment_never pay'] + X['payment_unknown']\n",
    "    X['Management_Risk**2'] = X['Management_Risk'] ** 2\n",
    "    \n",
    "    X['Non_Func_Risk'] = X['Condition_Risk'] + X['Tech_Risk'] + X['Management_Risk']\n",
    "    X['Non_Func_Risk*Pump_age'] = X['Non_Func_Risk'] * X['pump_age']\n",
    "    X['Non_Func_Risk**2'] = X['Non_Func_Risk'] ** 2\n",
    "    \n",
    "    X['Tech_Repair_Score'] = X['source_class_surface'] + X['extraction_type_class_gravity']\n",
    "    X['Tech_Repair_Score**2'] = X['Tech_Repair_Score'] ** 2\n",
    "    \n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = non_func_features(X_train)\n",
    "# X_val = non_func_features(X_val)\n",
    "# X_test = non_func_features(X_test)\n",
    "\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "def standardize(X):\n",
    "    # Features to standardize\n",
    "    standardize_cols = ['amount_tsh', 'gps_height', 'longitude', 'distance', ''\n",
    "                        'latitude', 'population', 'pump_age', 'pop*amount_tsh', 'pop/amount_tsh', \n",
    "                        'gps_height**2', 'gps_height**3', 'latitude*height*amount', 'latitude*height',\n",
    "                       'gps_height_binned', 'amount_tsh_binned', 'longitude_binned', 'latitude_binned']\n",
    "    cols = X.columns.tolist()\n",
    "    # Silence Data Conversion warning\n",
    "    X[standardize_cols] = X[standardize_cols].astype(float)\n",
    "    \n",
    "    # Fit and transform scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    scaled = pd.DataFrame( scaler.transform(X) )\n",
    "    \n",
    "    # Add back column names\n",
    "    for i in range(len(cols)):\n",
    "        scaled = scaled.rename(columns={i:cols[i]})\n",
    "        \n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = standardize(X_train)\n",
    "# X_val = standardize(X_val)\n",
    "# X_test = standardize(X_test)\n",
    "\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(y_test_pred):\n",
    "    sample_submission = pd.read_csv('Data/sample_submission.csv')\n",
    "    submission = sample_submission.copy()\n",
    "    submission['status_group'] = y_test_pred\n",
    "    \n",
    "    now = pd.to_datetime('now')\n",
    "    filename = 'MB_' + str(now).replace(' ','_')[0:-7] \n",
    "    \n",
    "    submission.to_csv(f'Submissions/{filename}.csv', index=False)\n",
    "    print(f'Submissions/{filename}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics \n",
    "- Function to capture snapshot of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, log_loss, f1_score, mean_absolute_error, mean_squared_error \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_metrics(fit_estimator, X, y):\n",
    "    '''\n",
    "    Evaluates classifiers performance across several metrics (accuracy, roc_auc, confusion matrix,\n",
    "                                                              log loss, f1, mean absolute error, \n",
    "                                                              mean squared error)\n",
    "    Parameters:\n",
    "        fit_estimator: an sklearn estimator that has been fitted to train data\n",
    "        X: the features with which predictions will be based on\n",
    "        y: the labels with which performance will be evaluated\n",
    "    Returns: \n",
    "        Prints summary of performance across metrics and visualizaiton of ROC curve\n",
    "    '''\n",
    "    score = fit_estimator.score(X, y)\n",
    "    y_pred = fit_estimator.predict(X)\n",
    "    y_pred_proba = fit_estimator.predict_proba(X)[:,1]\n",
    "    \n",
    "    name = fit_estimator.__class__.__name__\n",
    "    print(name)\n",
    "    print('Accuracy Score:', score)\n",
    "    print('F1 Score:', f1_score(y, y_pred, average='weighted'))\n",
    "\n",
    "    conf_mat = pd.DataFrame(confusion_matrix(y, y_pred), columns=['Predicted Functional', 'Predicted Needs Repair', 'Predicted Non-Functional'],\n",
    "                           index=['Actual Functional','Actual Needs Repair', 'Actual Non-Functional'])\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.07, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=400,\n",
       "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grboost = XGBClassifier(learning_rate=0.07, booster = 'gbtree', n_estimators=400, max_depth = 4)\n",
    "\n",
    "grboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_boost= grboost.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_boost = grboost.predict(X_val, ntree_limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936658249158249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "accuracy_score(y_train, y_train_pred_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7364478114478115"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_boost = grboost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubmissionsMB_2019-05-22_20:26:28.csv\n"
     ]
    }
   ],
   "source": [
    "create_submission(y_test_pred_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "search = cross_validate(ada, \n",
    "                        X_train, \n",
    "                        y_train, \n",
    "                        return_train_score=True,\n",
    "                        return_estimator=True,\n",
    "                        scoring='accuracy', \n",
    "                        n_jobs=-1,\n",
    "                        verbose=10,\n",
    "                        cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.621589</td>\n",
       "      <td>17.280218</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.742071</td>\n",
       "      <td>0.742071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.635195</td>\n",
       "      <td>17.111658</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.739596</td>\n",
       "      <td>0.741995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.662782</td>\n",
       "      <td>17.122066</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.741212</td>\n",
       "      <td>0.742551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time                                          estimator  \\\n",
       "0  101.621589   17.280218  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1  100.635195   17.111658  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "2  100.662782   17.122066  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "\n",
       "   test_score  train_score  \n",
       "0    0.742071     0.742071  \n",
       "1    0.739596     0.741995  \n",
       "2    0.741212     0.742551  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( search )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames of  submissions to ensemble\n",
    "files = ['submission-01.csv', 'submission-02.csv', 'submission-03.csv']\n",
    "\n",
    "def create_ensemble_submission(files):\n",
    "    submissions = (pd.read_csv(file)[['status_group']] for file in files)\n",
    "    ensemble = pd.concat(submissions, axis='columns')\n",
    "    majority_vote = ensemble.mode(axis='columns')[0]\n",
    "\n",
    "    sample_submission = pd.read_csv('sample_submission.csv')\n",
    "    submission = sample_submission.copy()\n",
    "    submission['status_group'] = majority_vote\n",
    "    \n",
    "    now = pd.to_datetime('now')\n",
    "    filename = 'MB_' + str(now).replace(' ','_')[0:-7]\n",
    "    \n",
    "    submission.to_csv('Submissions/{filename}.csv', index=False)\n",
    "    print(f'Submissions/{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', model),\n",
    "    ('grboost', grboost),\n",
    "]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, n_jobs=-1, voting='soft', weights=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=12,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=400,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=10...\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            learning_rate=0.07,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            min_child_weight=1, missing=None,\n",
       "                                            n_estimators=300, n_jobs=-1,\n",
       "                                            nthread=None,\n",
       "                                            objective='multi:softprob',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            seed=None, silent=False,\n",
       "                                            subsample=1))],\n",
       "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
       "                 weights=[1, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(processed_train, target['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "ensemble_train_predict = ensemble.predict(processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "ensemble_test_predict = ensemble.predict(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'functional', 'functional', ..., 'functional',\n",
       "       'functional', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8261447811447812"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target['status_group'], ensemble_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(ensemble_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
